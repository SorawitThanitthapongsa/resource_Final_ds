{"cells":[{"cell_type":"markdown","source":["# Image classificartion with EfficientNetB0\n","<br>Last updated on 10/02/2023</br>\n","<br>Objective: We aim to classify images into 10 classes of custom animal dataset using EfficientNetB0</br>\n","credit:<br>\n","https://pytorch.org/tutorials/beginner/data_loading_tutorial.html<br>\n","https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html<br>\n","https://www.kaggle.com/datasets/alessiocorrado99/animals10<br>"],"metadata":{"id":"DQePlnWfBRXX"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ekk2JN6CxGaO","outputId":"9d44c2b8-ac42-46b1-ed4d-751effd52d48","executionInfo":{"status":"ok","timestamp":1678026979561,"user_tz":-420,"elapsed":8,"user":{"displayName":"Sorawit Thanitthapongsa","userId":"06143032189547517260"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n","\n"]}],"source":["! nvidia-smi"]},{"cell_type":"markdown","source":["Download dataset"],"metadata":{"id":"j4REbT4iaHQk"}},{"cell_type":"code","source":["!wget https://github.com/pvateekul/2110446_DS_2022s2/raw/main/code/Week05_Intro_Deep_learning/Dataset_animal2.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zn6ZZzyOlQmE","executionInfo":{"status":"ok","timestamp":1678026980612,"user_tz":-420,"elapsed":1055,"user":{"displayName":"Sorawit Thanitthapongsa","userId":"06143032189547517260"}},"outputId":"2478b32e-e7c6-4443-fa4a-fa44d01b00ee"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-03-05 14:36:18--  https://github.com/pvateekul/2110446_DS_2022s2/raw/main/code/Week05_Intro_Deep_learning/Dataset_animal2.zip\n","Resolving github.com (github.com)... 140.82.114.4\n","Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n","HTTP request sent, awaiting response... 404 Not Found\n","2023-03-05 14:36:19 ERROR 404: Not Found.\n","\n"]}]},{"cell_type":"code","source":["!unzip -q -o 'Dataset_animal2.zip' "],"metadata":{"id":"xPUhMGQglliJ","executionInfo":{"status":"ok","timestamp":1678026980612,"user_tz":-420,"elapsed":9,"user":{"displayName":"Sorawit Thanitthapongsa","userId":"06143032189547517260"}},"outputId":"3063e198-6912-4443-85e2-7ba2591702cc","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["unzip:  cannot find or open Dataset_animal2.zip, Dataset_animal2.zip.zip or Dataset_animal2.zip.ZIP.\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"qb6KuD9sjfvS","executionInfo":{"status":"ok","timestamp":1678026981654,"user_tz":-420,"elapsed":1045,"user":{"displayName":"Sorawit Thanitthapongsa","userId":"06143032189547517260"}}},"outputs":[],"source":["from sklearn.exceptions import UndefinedMetricWarning\n","\n","def warn(*args, **kwargs):\n","    pass\n","import warnings\n","warnings.warn = warn"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Cxvk1XNtwxN7","executionInfo":{"status":"ok","timestamp":1678026989308,"user_tz":-420,"elapsed":7656,"user":{"displayName":"Sorawit Thanitthapongsa","userId":"06143032189547517260"}}},"outputs":[],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset\n","from PIL import Image\n","import os"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"arYMLNHx0W5r","outputId":"ae2b65dc-040a-4c41-a615-5597b2f42919","executionInfo":{"status":"ok","timestamp":1678026989906,"user_tz":-420,"elapsed":603,"user":{"displayName":"Sorawit Thanitthapongsa","userId":"06143032189547517260"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}],"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","# Assuming that we are on a CUDA machine, this should print a CUDA device:\n","\n","print(device)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"FabhyQJBBYnx","executionInfo":{"status":"ok","timestamp":1678026994538,"user_tz":-420,"elapsed":4634,"user":{"displayName":"Sorawit Thanitthapongsa","userId":"06143032189547517260"}}},"outputs":[],"source":["import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","transform_train = transforms.Compose(\n","    [transforms.Resize((230,230)),\n","        transforms.RandomRotation(30,),\n","        transforms.RandomCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomVerticalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276]) #nomalize imagenet pretrain\n","    ])\n","\n","transform = transforms.Compose(\n","    [transforms.Resize((224,224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])\n","    ])\n","\n","batch_size = 32"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"4IRbDPG2xQvo","executionInfo":{"status":"error","timestamp":1678026996627,"user_tz":-420,"elapsed":2093,"user":{"displayName":"Sorawit Thanitthapongsa","userId":"06143032189547517260"}},"outputId":"19256a5f-1511-452a-c47d-0de4e44eb905","colab":{"base_uri":"https://localhost:8080/","height":357}},"outputs":[{"output_type":"error","ename":"StopIteration","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-f383a6f59a1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mtrainset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAnimalDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Dataset_animal2/train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mvalset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAnimalDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Dataset_animal2/val'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAnimalDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Dataset_animal2/test'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-f383a6f59a1e>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img_dir, transforms)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlabel_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel_image\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mimage_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_num\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# [image_path, label_num]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mStopIteration\u001b[0m: "]}],"source":["class AnimalDataset(Dataset):\n","    \n","    def __init__(self, \n","                 img_dir, \n","                 transforms=None):\n","        \n","        super().__init__()\n","        label_image = ['butterfly','cat','chicken','cow','dog','elephant','horse','sheep','spider','squirrel']\n","        self.input_dataset = list()\n","        label_num = 0\n","        for label in label_image:\n","            _, _, files = next(os.walk(os.path.join(img_dir,label)))\n","            for image_name in files:\n","                input = [os.path.join(img_dir,label,image_name),label_num] # [image_path, label_num]\n","                self.input_dataset.append(input)\n","            label_num += 1\n","        \n","        self.transforms = transforms\n","\n","    def __len__(self):\n","        return len(self.input_dataset)\n","\n","    def __getitem__(self, idx): \n","        img = Image.open(self.input_dataset[idx][0]).convert('RGB')\n","        x = self.transforms(img)\n","        y = self.input_dataset[idx][1]\n","        return x,y\n","\n","trainset = AnimalDataset('./Dataset_animal2/train',transform_train)\n","valset = AnimalDataset('./Dataset_animal2/val',transform)\n","testset = AnimalDataset('./Dataset_animal2/test',transform)\n","\n","\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n","valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n","\n","#classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Igfnh4pXjfvW","executionInfo":{"status":"aborted","timestamp":1678026996627,"user_tz":-420,"elapsed":5,"user":{"displayName":"Sorawit Thanitthapongsa","userId":"06143032189547517260"}}},"outputs":[],"source":["trainset.__len__(), valset.__len__(), testset.__len__()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TA-3nvKQzx_i","executionInfo":{"status":"aborted","timestamp":1678026996627,"user_tz":-420,"elapsed":5,"user":{"displayName":"Sorawit Thanitthapongsa","userId":"06143032189547517260"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# functions to show an image\n","def imshow(img):\n","    img = img*torch.tensor([0.267, 0.256, 0.276]).mean() + torch.tensor([0.507, 0.487, 0.441]).mean()     # unnormalize\n","    npimg = img.numpy()\n","    plt.figure(figsize=(16,16))\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()\n","\n","# get some random training images\n","dataiter = iter(trainloader)\n","images, labels = next(dataiter)\n","\n","# show images\n","nrow = 9\n","imshow(torchvision.utils.make_grid(images, nrow = nrow))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VmNRvP5VJFmt","executionInfo":{"status":"aborted","timestamp":1678026996627,"user_tz":-420,"elapsed":5,"user":{"displayName":"Sorawit Thanitthapongsa","userId":"06143032189547517260"}}},"outputs":[],"source":["# print labels\n","for i in range(batch_size//nrow + 1 if batch_size % nrow else 0):\n","  print(' '.join(f'{labels[i*nrow+j]:<3}' for j in range(min(batch_size - i*nrow, nrow))))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yiM5v7iuz1IC","executionInfo":{"status":"aborted","timestamp":1678026996627,"user_tz":-420,"elapsed":5,"user":{"displayName":"Sorawit Thanitthapongsa","userId":"06143032189547517260"}}},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","#pretrain_weight = torchvision.models.EfficientNet_V2_S_Weights.IMAGENET1K_V1\n","#net = torchvision.models.efficientnet_v2_s(weights = pretrain_weight)\n","#net.classifier[1] = nn.Linear(1280, 102)\n","#net = net.to(device)\n","#mobile_net \n","num_classes=10\n","model_ft = torchvision.models.efficientnet_b0(pretrained=True)\n","model_ft.classifier[-1] = nn.Sequential(\n","    nn.Linear(in_features=1280, out_features=num_classes),\n","    nn.Softmax(dim=1)\n","        )\n","\n","net = model_ft.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"npHTcpR24sI3","executionInfo":{"status":"aborted","timestamp":1678026996628,"user_tz":-420,"elapsed":6,"user":{"displayName":"Sorawit Thanitthapongsa","userId":"06143032189547517260"}}},"outputs":[],"source":["from torchsummary import summary\n","summary(net, (3, 224, 224), batch_size = 64)\n","#from torchinfo import summary as summary_info\n","#summary_info(net, input_size = (128, 3, 224, 224))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P5Hyi14cz3x_","executionInfo":{"status":"aborted","timestamp":1678026996628,"user_tz":-420,"elapsed":5,"user":{"displayName":"Sorawit Thanitthapongsa","userId":"06143032189547517260"}}},"outputs":[],"source":["import torch.optim as optim\n","from torch.optim import lr_scheduler\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.02, momentum=0.9)\n","scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wtpjzmgAz6Ru","scrolled":true,"executionInfo":{"status":"aborted","timestamp":1678026996628,"user_tz":-420,"elapsed":5,"user":{"displayName":"Sorawit Thanitthapongsa","userId":"06143032189547517260"}}},"outputs":[],"source":["from sklearn.metrics import classification_report\n","from tqdm.notebook import tqdm\n","\n","\n","epochs = 20\n","\n","history_train = {'loss':np.zeros(epochs), 'acc':np.zeros(epochs), 'f1-score':np.zeros(epochs)}\n","history_val = {'loss':np.zeros(epochs), 'acc':np.zeros(epochs), 'f1-score':np.zeros(epochs)}\n","min_val_loss = 1e10\n","PATH = './Animal10-efficientnetb0.pth'\n","\n","for epoch in range(epochs):  # loop over the dataset multiple times\n","    \n","    print(f'epoch {epoch + 1} \\nTraining ...')\n","    net.train()\n","    y_predict = list()\n","    y_labels = list()\n","    training_loss = 0.0\n","    n = 0\n","    with torch.set_grad_enabled(True):\n","        for data in tqdm(trainloader):\n","            \n","            # get the inputs; data is a list of [inputs, labels]\n","            inputs, labels = data\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # forward + backward + optimize\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            # aggregate statistics\n","            training_loss += loss.item()\n","            n+=1\n","\n","            y_labels += list(labels.cpu().numpy())\n","            y_predict += list(outputs.argmax(dim=1).cpu().numpy())\n","    scheduler.step()\n","\n","    # print statistics\n","    report = classification_report(y_labels, y_predict, digits = 4, output_dict = True)\n","    acc = report[\"accuracy\"]\n","    f1 = report[\"weighted avg\"][\"f1-score\"]\n","    support = report[\"weighted avg\"][\"support\"]\n","    training_loss /= n\n","    print(f\"training loss: {training_loss:.4}, acc: {acc*100:.4}%, f1-score: {f1*100:.4}%, support: {support}\" )\n","    history_train['loss'][epoch] = training_loss\n","    history_train['acc'][epoch] = acc\n","    history_train['f1-score'][epoch] = f1\n","\n","    print('validating ...')\n","    net.eval()\n","    \n","    optimizer.zero_grad()\n","    \n","    y_predict = list()\n","    y_labels = list()\n","    validation_loss = 0.0\n","    n = 0\n","    with torch.no_grad():\n","        for data in tqdm(valloader):\n","            inputs, labels = data\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            validation_loss += loss.item()\n","\n","            y_labels += list(labels.cpu().numpy())\n","            y_predict += list(outputs.argmax(dim=1).cpu().numpy())\n","            n+=1\n","\n","    # print statistics\n","    report = classification_report(y_labels, y_predict, digits = 4, output_dict = True)\n","    acc = report[\"accuracy\"]\n","    f1 = report[\"weighted avg\"][\"f1-score\"]\n","    support = report[\"weighted avg\"][\"support\"]\n","    validation_loss /= n\n","    print(f\"validation loss: {validation_loss:.4}, acc: {acc*100:.4}%, f1-score: {f1*100:.4}%, support: {support}\" )\n","    history_val['loss'][epoch] = validation_loss\n","    history_val['acc'][epoch] = acc\n","    history_val['f1-score'][epoch] = f1\n","    \n","    #save min validation loss\n","    if validation_loss < min_val_loss:\n","        torch.save(net.state_dict(), PATH)\n","        min_val_loss = validation_loss     \n","    \n","print('Finished Training')"]},{"cell_type":"code","source":["min_val_loss"],"metadata":{"id":"97Y1L-1vpZTk","executionInfo":{"status":"aborted","timestamp":1678026996628,"user_tz":-420,"elapsed":5,"user":{"displayName":"Sorawit Thanitthapongsa","userId":"06143032189547517260"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, axs = plt.subplots(3, figsize= (6,10))\n","# loss\n","axs[0].plot(history_train['loss'], label = 'training')\n","axs[0].plot(history_val['loss'], label = 'validation')\n","axs[0].set_title(\"loss\")\n","axs[0].legend()\n","# acc\n","axs[1].plot(history_train['acc'], label = 'training')\n","axs[1].plot(history_val['acc'], label = 'validation')\n","axs[1].set_title(\"acc\")\n","axs[1].legend()\n","# f1-score\n","axs[2].plot(history_train['f1-score'], label = 'training')\n","axs[2].plot(history_val['f1-score'], label = 'validation')\n","axs[2].set_title(\"f1-score\")\n","axs[2].legend()\n","plt.show()"],"metadata":{"id":"993VrUFblBS1","executionInfo":{"status":"aborted","timestamp":1678026996628,"user_tz":-420,"elapsed":5,"user":{"displayName":"Sorawit Thanitthapongsa","userId":"06143032189547517260"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mJAMXJvI0GhA","executionInfo":{"status":"aborted","timestamp":1678026996628,"user_tz":-420,"elapsed":5,"user":{"displayName":"Sorawit Thanitthapongsa","userId":"06143032189547517260"}}},"outputs":[],"source":["PATH = './Animal10-efficientnetb0.pth'\n","net.load_state_dict(torch.load(PATH))"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"9CA_ElQdjfvh","executionInfo":{"status":"aborted","timestamp":1678026996628,"user_tz":-420,"elapsed":5,"user":{"displayName":"Sorawit Thanitthapongsa","userId":"06143032189547517260"}}},"outputs":[],"source":["from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n","\n","\n","print('testing ...')\n","y_predict = list()\n","y_labels = list()\n","test_loss = 0.0\n","n = 0\n","with torch.no_grad():\n","    for data in tqdm(testloader):\n","        net.eval()\n","        inputs, labels = data\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        test_loss += loss.item()\n","\n","        y_labels += list(labels.cpu().numpy())\n","        y_predict += list(outputs.argmax(dim=1).cpu().numpy())\n","        n+=1\n","\n","    # print statistics\n","    test_loss /= n\n","    print(f\"testing loss: {test_loss:.4}\" )\n","    \n","    report = classification_report(y_labels, y_predict, digits = 4)\n","    M = confusion_matrix(y_labels, y_predict)\n","    print(report)\n","    disp = ConfusionMatrixDisplay(confusion_matrix=M)"]},{"cell_type":"code","source":["disp.plot()\n","plt.show()"],"metadata":{"id":"LAMjMggjR2a1","executionInfo":{"status":"aborted","timestamp":1678026996628,"user_tz":-420,"elapsed":5,"user":{"displayName":"Sorawit Thanitthapongsa","userId":"06143032189547517260"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/pvateekul/2110446_DS_2022s2/blob/main/code/Week05_Intro_Deep_learning/2_Image_classification-Animal-EfficientNetB0.ipynb","timestamp":1678000546988},{"file_id":"1OQavEAPfjoDKBDwSu55_Xr1DCcbSPrRq","timestamp":1675935321317}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}